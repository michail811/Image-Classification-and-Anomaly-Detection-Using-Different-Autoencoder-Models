{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Image Classification and Anomaly Detection of a Custom Dataset Using Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "EnKWQ4Cp0efF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "5aatwxSX1B3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import utils\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "from pathlib import Path\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras import backend as K\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "c4QvWiAr0Yt0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unizip images"
      ],
      "metadata": {
        "id": "MgXQcC8ao9dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unzip images\n",
        "! unzip good.zip\n",
        "! unzip bad.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6J71ZQHp1JD",
        "outputId": "78845996-c951-41ed-ce45-d9170ac3f64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  good.zip\n",
            "replace good/Image00000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The image classifier class includes 4 different models.\n",
        "\n",
        "\n",
        "1.   binary classification with vgg16 transfer learning\n",
        "2.   simple mlp autoencoder\n",
        "3.   cnn autoencoder\n",
        "4.   cnn with vgg16 transfer learning modified autoencoder\n",
        "\n",
        "# It also includes visualization, evaluation functions like accuracy etc for the classification and the reconstruction error is being used as a metric for the autoencoders networks.\n",
        "\n"
      ],
      "metadata": {
        "id": "r23KlPtenWcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassifier:\n",
        "    def __init__(self, input_shape=(100, 100, 3),model_type='vgg16_transfer_learning'):\n",
        "        self.input_shape = input_shape\n",
        "        self.model_type = model_type\n",
        "        self.model = self.build_model()\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        if self.model_type == 'vgg16_transfer_learning':\n",
        "            return self.build_model_vgg16_transfer_learning()\n",
        "\n",
        "        elif self.model_type == 'simple_mlp_autoencoder':\n",
        "            return self.build_model_simple_mlp_autoencoder()\n",
        "\n",
        "        elif self.model_type == 'cnn_autoencoder':\n",
        "            return self.build_model_autoencoder_cnn()\n",
        "\n",
        "        elif self.model_type == 'cnn_with_vgg16_modified_autoencoder':\n",
        "            return self.build_model__modified_autoencoder_vgg16()\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid model type\")\n",
        "\n",
        "    def build_model_vgg16_transfer_learning(self):\n",
        "        base_model = VGG16(weights='imagenet', input_shape=self.input_shape, include_top=False)\n",
        "        base_model.trainable = False\n",
        "\n",
        "        inputs = keras.Input(shape=self.input_shape)\n",
        "        x = base_model(inputs, training=False)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        self.model = Model(inputs, outputs)\n",
        "\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def build_model_simple_mlp_autoencoder(self):\n",
        "\n",
        "        encoded_dim = 32  # encoding dimension\n",
        "\n",
        "        # Encoder\n",
        "        input_img = Input(shape=self.input_shape)\n",
        "        flatten_img = keras.layers.Flatten()(input_img)\n",
        "        encoded = Dense(encoded_dim, activation='relu')(flatten_img)\n",
        "\n",
        "        # Decoder\n",
        "        decoded = Dense(self.input_shape[0] * self.input_shape[1] * self.input_shape[2], activation='sigmoid')(encoded)\n",
        "        decoded_img = keras.layers.Reshape(self.input_shape)(decoded)\n",
        "\n",
        "        # Create the autoencoder model\n",
        "        self.autoencoder = Model(input_img, decoded_img)\n",
        "\n",
        "\n",
        "\n",
        "    def build_model_autoencoder_cnn(self):\n",
        "        # Encoder\n",
        "        input_img = Input(shape=self.input_shape)\n",
        "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
        "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "\n",
        "        # Decoder\n",
        "        x = Conv2D(2, (3, 3), activation='relu', padding='same')(encoded)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "        self.autoencoder = Model(input_img, decoded)\n",
        "\n",
        "\n",
        "\n",
        "    def build_model__modified_autoencoder_vgg16(self):\n",
        "        # Load pre-trained VGG16 model as an encoder\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
        "\n",
        "        # Freeze the layers of the encoder\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Encoder\n",
        "        encoder_output = base_model.output\n",
        "\n",
        "        # Decoder\n",
        "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)  # Changed from (2, 2) to (2, 2)\n",
        "        x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)  # Additional upsampling layer\n",
        "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "        # Create the autoencoder model\n",
        "        self.autoencoder = Model(inputs=base_model.input, outputs=decoded)\n",
        "\n",
        "\n",
        "    def compile_model(self, learning_rate=0.001):\n",
        "\n",
        "        if self.model_type == 'vgg16_transfer_learning':\n",
        "            adam = Adam(learning_rate=learning_rate)\n",
        "            self.model.compile(loss='binary_crossentropy', optimizer=adam, metrics=(['accuracy'],['Recall'],['Precision']))\n",
        "\n",
        "        elif self.model_type == 'simple_mlp_autoencoder':\n",
        "            self.autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "        elif self.model_type == 'cnn_autoencoder':\n",
        "            optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "            def ssim_loss(y_true, y_pred):\n",
        "                return 1.0 - tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
        "\n",
        "            # Compile model with the custom loss, Structural Similarity Index(SSIM).\n",
        "            self.autoencoder.compile(optimizer=optimizer, loss=ssim_loss, metrics=['MSE', 'MAE'])\n",
        "\n",
        "        elif self.model_type == 'cnn_with_vgg16_modified_autoencoder':\n",
        "            # Compile the model and specify the appropriate loss function and optimizer\n",
        "            self.autoencoder.compile(optimizer='adam', loss='mse', metrics=['MSE', 'MAE'])\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid model type\")\n",
        "\n",
        "\n",
        "    def train_model(self, x_train, y_train, x_test, y_test, batch_size=16, epochs=100, good_images=None):\n",
        "        # if it is classic classification, good images are not needed. Autoencoders for anomaly detection are trained only with the good images.\n",
        "        if good_images is not None:\n",
        "            good_images=good_images\n",
        "\n",
        "        if self.model_type == 'vgg16_transfer_learning' :\n",
        "            save_model = ModelCheckpoint('model_checkpoint.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
        "\n",
        "            self.datagen = ImageDataGenerator(featurewise_center=True,samplewise_center=True,rotation_range=10,zoom_range=0.1,width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True,vertical_flip=False)\n",
        "\n",
        "            self.datagen.fit(x_train)\n",
        "\n",
        "            self.data = self.model.fit(self.datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                                steps_per_epoch=len(x_train) / batch_size, epochs=epochs,\n",
        "                                validation_data=(x_test, y_test),\n",
        "                                shuffle=True,\n",
        "                                callbacks=[save_model])\n",
        "\n",
        "        elif self.model_type ==  'simple_mlp_autoencoder':\n",
        "            self.autoencoder.fit(good_images, good_images, epochs=50, batch_size=16, shuffle=True, validation_split=0.3)\n",
        "\n",
        "        elif self.model_type == 'cnn_autoencoder':\n",
        "            self.autoencoder.fit(good_images, good_images, epochs=100, batch_size=16, shuffle=True, validation_split=0.2)\n",
        "\n",
        "        elif self.model_type == 'cnn_with_vgg16_modified_autoencoder':\n",
        "            self.autoencoder.fit(good_images, good_images, epochs=50, batch_size=2)\n",
        "\n",
        "    def load_images(self, directory, label, shape=(100, 100)):\n",
        "        images = []\n",
        "        labels = []\n",
        "        for filename in os.listdir(directory):\n",
        "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                path = os.path.join(directory, filename)\n",
        "                img = cv2.imread(path)\n",
        "                img = cv2.resize(img, shape)\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "    def load_dataset(self, good_dir, bad_dir, test_size=0.2, random_seed=42):\n",
        "        good_images, good_labels = self.load_images(good_dir, label=0)\n",
        "        bad_images, bad_labels = self.load_images(bad_dir, label=1)\n",
        "\n",
        "        all_images = np.concatenate((good_images, bad_images), axis=0)\n",
        "        all_labels = np.concatenate((good_labels, bad_labels), axis=0)\n",
        "\n",
        "        all_images = all_images.astype('float32') / 255.0\n",
        "\n",
        "        np.random.seed(random_seed)\n",
        "        tf.random.set_seed(random_seed)\n",
        "\n",
        "        x_train, x_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=test_size, random_state=random_seed)\n",
        "\n",
        "        return x_train, x_test, y_train, y_test, good_images, bad_images\n",
        "\n",
        "    def resize_data(self, good_images, bad_images,target_size):\n",
        "\n",
        "        good_images = [img_to_array(array_to_img(img).resize(target_size)) for img in good_images]\n",
        "        bad_images = [img_to_array(array_to_img(img).resize(target_size)) for img in bad_images]\n",
        "\n",
        "        good_images=np.array(good_images)\n",
        "        bad_images=np.array(bad_images)\n",
        "\n",
        "        good_images = good_images.astype('float32') / 255.0\n",
        "        bad_images = bad_images.astype('float32') / 255.0\n",
        "\n",
        "\n",
        "        return good_images, bad_images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_metrics_classification(self, data):\n",
        "        plt.plot(self.data.history['accuracy'])\n",
        "        plt.plot(self.data.history['val_accuracy'])\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(self.data.history['val_precision'])\n",
        "        plt.title('Validation Precision')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(self.data.history['loss'])\n",
        "        plt.plot(self.data.history['val_loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict_classification(self, data):\n",
        "        return self.model.predict(data)\n",
        "\n",
        "    def predict_autoencoder(self, good_images, bad_images):\n",
        "\n",
        "        with tf.device('/CPU:0'):\n",
        "            predictions = self.autoencoder.predict(bad_images)\n",
        "            good_predictions = self.autoencoder.predict(good_images)\n",
        "\n",
        "        return predictions,  good_predictions\n",
        "\n",
        "    def predict_an_image_autoencoder(self,image):\n",
        "        reconstructed_image = self.autoencoder.predict(image)[0]\n",
        "        return reconstructed_image\n",
        "\n",
        "    def evaluate_classification(self, y_test, binary_predictions):\n",
        "        cm = confusion_matrix(y_test, binary_predictions)\n",
        "        self.plot_confusion_matrix(cm)\n",
        "\n",
        "        TP, FP, TN, FN = cm.ravel()\n",
        "        accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "        precision = TP / (TP + FP)\n",
        "        recall = TP / (TP + FN)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1 Score: {f1_score:.2f}\")\n",
        "        return cm\n",
        "\n",
        "    def evaluate_autoencoder(self, good_images, bad_images, good_predictions, bad_predictions,threshold ):\n",
        "\n",
        "        # Calculate reconstruction loss (e.g., mean squared error) between original and reconstructed images\n",
        "        reconstruction_loss = np.mean(np.square(bad_images - bad_predictions), axis=(1, 2, 3))\n",
        "\n",
        "        # Calculate reconstruction loss for good images\n",
        "        good_reconstruction_loss = np.mean(np.square(good_images - good_predictions), axis=(1, 2, 3))\n",
        "\n",
        "        # Classify images as normal or anomaly based on the threshold\n",
        "        anomaly_predictions = (reconstruction_loss > threshold).astype(int)\n",
        "\n",
        "        # sum\n",
        "        sum_anomaly_predictions = np.sum((reconstruction_loss > threshold).astype(int))\n",
        "\n",
        "        # Classify images as anomaly based on the threshold\n",
        "        anomaly_predictions_of_good_images = (good_reconstruction_loss > threshold).astype(int)\n",
        "\n",
        "\n",
        "        # Classify images as good based on the threshold\n",
        "        sum_anomaly_predictions_of_good_images = np.sum((good_reconstruction_loss < threshold).astype(int))\n",
        "\n",
        "        print('found from',bad_images.shape[0],'total bad images, the images with anomalies are:',sum_anomaly_predictions )\n",
        "        print('found from',good_images.shape[0],'total good images, the good images are',sum_anomaly_predictions_of_good_images )\n",
        "\n",
        "        # Plot histogram of reconstruction errors for good images\n",
        "        plt.hist(good_reconstruction_loss, bins=50, label='Good Images', alpha=0.5)\n",
        "        plt.hist(reconstruction_loss, bins=50, label='Bad Images', alpha=0.5)\n",
        "        plt.title('Reconstruction Loss Histogram')\n",
        "        plt.xlabel('Reconstruction Loss')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        all_reconstruction_error=np.array([])\n",
        "        for i in range(20):\n",
        "            original_image = good_images[i]\n",
        "\n",
        "            # Reshape the image to match the input shape of the autoencoder\n",
        "            original_image = np.expand_dims(original_image, axis=0)\n",
        "            with tf.device('/CPU:0'):\n",
        "                reconstructed_image = self.predict_an_image_autoencoder(original_image)\n",
        "\n",
        "            reconstruction_error=np.mean(np.square(original_image - reconstructed_image))\n",
        "            all_reconstruction_error = np.append(all_reconstruction_error, reconstruction_error)\n",
        "            plt.figure(figsize=(8, 4))\n",
        "\n",
        "            # Original image\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(original_image[0])\n",
        "            plt.title('Original images')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Reconstructed image\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(reconstructed_image)\n",
        "            plt.title('Reconstructed Image')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()\n",
        "        print('loss for good',all_reconstruction_error)\n",
        "\n",
        "        all_reconstruction_error_bad=np.array([])\n",
        "        for i in range(20):\n",
        "            original_image = bad_images[i]\n",
        "\n",
        "            # Reshape the image to match the input shape of the autoencoder\n",
        "            original_image = np.expand_dims(original_image, axis=0)\n",
        "            with tf.device('/CPU:0'):\n",
        "                reconstructed_image = self.predict_an_image_autoencoder(original_image)\n",
        "\n",
        "            reconstruction_error_bad=np.mean(np.square(original_image - reconstructed_image))\n",
        "            all_reconstruction_error_bad=np.append(all_reconstruction_error_bad, reconstruction_error_bad)\n",
        "\n",
        "            plt.figure(figsize=(8, 4))\n",
        "\n",
        "            # Original image\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(original_image[0])\n",
        "            plt.title('Original images')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Reconstructed image\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(reconstructed_image)\n",
        "            plt.title('Reconstructed Image')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()\n",
        "        print('loss for bad',all_reconstruction_error_bad)\n",
        "\n",
        "        return reconstruction_loss, good_reconstruction_loss\n",
        "\n",
        "    def plot_confusion_matrix(self, cm):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                    xticklabels=['Predicted Positive', 'Predicted Negative'],\n",
        "                    yticklabels=['Actual Positive', 'Actual Negative'])\n",
        "        plt.xlabel(\"Predicted Label\")\n",
        "        plt.ylabel(\"True Label\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "AamLAofYzUzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make different objects for each networks(classifier1, classifier2, ...)\n",
        "# The network is selected through:\n",
        "## ImageClassifier(input_shape=(100, 100, 3),model_type='MODEL NAME')\n",
        "## The model names are: vgg16_transfer_learning, simple_mlp_autoencoder, cnn_autoencoder, cnn_with_vgg16_modified_autoencoder."
      ],
      "metadata": {
        "id": "f0gfhRhJthSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# vgg16_transfer_learning\n",
        "\n",
        "def run_vgg16_transfer_learning():\n",
        "  classifier1 = ImageClassifier(input_shape=(100, 100, 3),model_type='vgg16_transfer_learning')\n",
        "  x_train, x_test, y_train, y_test, good_images, bad_images = classifier1.load_dataset(good_dir='./good/', bad_dir='./bad/')\n",
        "  classifier1.compile_model()\n",
        "  data = classifier1.train_model(x_train, y_train, x_test, y_test)\n",
        "  classifier1.plot_metrics_classification(data)\n",
        "  predictions_x_test = classifier1.predict_classification(x_test)\n",
        "  binary_predictions_x_test = (predictions_x_test > 0.5).astype(int)\n",
        "  classifier1.evaluate_classification(y_test, binary_predictions_x_test)\n",
        "\n",
        "\n",
        "\n",
        "# mlp autoencoder for anomaly detection\n",
        "\n",
        "def run_simple_mlp_autoencoder():\n",
        "  classifier2 = ImageClassifier(input_shape=(100, 100, 3),model_type='simple_mlp_autoencoder')\n",
        "  x_train, x_test, y_train, y_test, good_images, bad_images = classifier2.load_dataset(good_dir='./good/', bad_dir='./bad/')\n",
        "  target_size1=(100,100)\n",
        "  good_images, bad_images= classifier2.resize_data(good_images, bad_images,target_size1)\n",
        "  classifier2.compile_model()\n",
        "  classifier2.train_model(x_train, y_train, x_test, y_test,epochs=50, batch_size=16,good_images=good_images)\n",
        "  bad_predictions,good_predictions=classifier2.predict_autoencoder(good_images, bad_images)\n",
        "  reconstruction_loss, good_reconstruction_loss=classifier2.evaluate_autoencoder(good_images, bad_images, good_predictions, bad_predictions,threshold=0.01 )\n",
        "\n",
        "# cnn autoencoder for anomaly detection\n",
        "\n",
        "def run_cnn_autoencoder():\n",
        "  target_size2=(128,128)\n",
        "  input_shape=(128,128,3)\n",
        "  classifier3 = ImageClassifier(input_shape=input_shape,model_type='cnn_autoencoder')\n",
        "  x_train, x_test, y_train, y_test, good_images, bad_images = classifier3.load_dataset(good_dir='./good/', bad_dir='./bad/')\n",
        "  good_images, bad_images= classifier3.resize_data(good_images, bad_images,target_size2)\n",
        "  classifier3.compile_model()\n",
        "  classifier3.train_model(x_train, y_train, x_test, y_test,epochs=100, batch_size=16,good_images=good_images)\n",
        "  bad_predictions,good_predictions=classifier3.predict_autoencoder(good_images, bad_images)\n",
        "  reconstruction_loss, good_reconstruction_loss=classifier3.evaluate_autoencoder(good_images, bad_images, good_predictions, bad_predictions, threshold=0.015 )\n",
        "\n",
        "# modified autoencoder vgg16 for anomaly detection\n",
        "\n",
        "def run_cnn_with_vgg16_modified_autoencoder():\n",
        "  target_size3=(128,128)\n",
        "  input_shape=(128,128,3)\n",
        "  classifier4 = ImageClassifier(input_shape=input_shape,model_type='cnn_with_vgg16_modified_autoencoder')\n",
        "  x_train, x_test, y_train, y_test, good_images, bad_images = classifier4.load_dataset(good_dir='./good/', bad_dir='./bad/')\n",
        "  good_images, bad_images= classifier4.resize_data(good_images, bad_images,target_size3)\n",
        "  classifier4.compile_model()\n",
        "  classifier4.train_model(x_train, y_train, x_test, y_test,epochs=100, batch_size=16,good_images=good_images)\n",
        "  bad_predictions,good_predictions=classifier4.predict_autoencoder(good_images, bad_images)\n",
        "  reconstruction_loss, good_reconstruction_loss=classifier4.evaluate_autoencoder(good_images, bad_images, good_predictions, bad_predictions, threshold=0.005 )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qoBGhYfneBht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run_vgg16_transfer_learning"
      ],
      "metadata": {
        "id": "XvBBsv0rm9fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_vgg16_transfer_learning()\n"
      ],
      "metadata": {
        "id": "0ht2MiZjfKkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run_simple_mlp_autoencoder"
      ],
      "metadata": {
        "id": "eo6bNDtfm6nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_simple_mlp_autoencoder()"
      ],
      "metadata": {
        "id": "hmhjF16QfOk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run_cnn_autoencoder"
      ],
      "metadata": {
        "id": "AOlVSgICmvIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_cnn_autoencoder()"
      ],
      "metadata": {
        "id": "KLKGJqP0qmSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# run_cnn_with_vgg16_modified_autoencoder"
      ],
      "metadata": {
        "id": "hbQv-j_ympNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_cnn_with_vgg16_modified_autoencoder()"
      ],
      "metadata": {
        "id": "wfj3Fd_yfiVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}